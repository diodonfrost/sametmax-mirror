<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" >

<channel>
	<title>mysql &#8211; Sam &amp; Max</title>
	<atom:link href="http://sametmax.com/tag/mysql/feed/" rel="self" type="application/rss+xml" />
	<link>http://sametmax.com</link>
	<description>Du code, du cul</description>
	<lastBuildDate>Thu, 05 Sep 2019 08:22:03 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.7</generator>
<site xmlns="com-wordpress:feed-additions:1">32490438</site>	<item>
		<title>Django pleure &#8216;MySQL server has gone away&#8217;</title>
		<link>http://sametmax.com/django-pleure-mysql-server-has-gone-away/</link>
		<comments>http://sametmax.com/django-pleure-mysql-server-has-gone-away/#comments</comments>
		<pubDate>Mon, 13 Oct 2014 08:52:19 +0000</pubDate>
		<dc:creator><![CDATA[Sam]]></dc:creator>
				<category><![CDATA[Programmation]]></category>
		<category><![CDATA[django]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[python]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=12424</guid>
		<description><![CDATA[
Dans certaines circonstances, par exemple une transaction ouverte pendant trop longtemps, MySQL ferme la connexion avec son client. ]]></description>
				<content:encoded><![CDATA[<p>Dans certaines circonstances, par exemple une transaction ouverte pendant trop longtemps, MySQL ferme la connexion avec son client. </p>
<p>Cela arrive par exemple quand on l&#8217;utilise comme broker pour celery. On a des tâches qui plantent, et quand on met du debug, on lit un <code>(2006, 'MySQL server has gone away')</code> bien cryptique.</p>
<p>Généralement je recommande de changer de backend ici. Passer à redis pour cet usage par exemple.</p>
<p>Mais parfois on ne peut pas. La solution est alors de forcer Django à réinitialiser la connexion en la fermant. Il faut le faire au niveau où on a remarqué que la requête échouait. Dans notre cas, au début de chaque tâche celery :</p>
<pre lang="python">from django.db import connection 

@task
def do_stuff():
    connection.close()
    # le reste du code</pre>
<p>Voyant la connexion fermée, Django va en ouvrir une nouvelle à la prochaine requête automatiquement.</p>
<p>Cela a, évidement, un impact sur les performances, donc choisissez bien entre mettre une rustine et changer la roue.</p>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/django-pleure-mysql-server-has-gone-away/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">12424</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2014/10/keep-calm-cause-im-gone-away.png" length="38892" type="image/jpg" />	</item>
		<item>
		<title>NoSQL : arrêtons de dire n&#8217;importe quoi</title>
		<link>http://sametmax.com/nosql-arretons-de-dire-nimporte-quoi/</link>
		<comments>http://sametmax.com/nosql-arretons-de-dire-nimporte-quoi/#comments</comments>
		<pubDate>Sat, 22 Mar 2014 10:26:06 +0000</pubDate>
		<dc:creator><![CDATA[Sam]]></dc:creator>
				<category><![CDATA[Administration System]]></category>
		<category><![CDATA[cassandra]]></category>
		<category><![CDATA[couchdb]]></category>
		<category><![CDATA[elastic search]]></category>
		<category><![CDATA[memecache]]></category>
		<category><![CDATA[mongodb]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[nosql]]></category>
		<category><![CDATA[postgre]]></category>
		<category><![CDATA[redis]]></category>
		<category><![CDATA[riak]]></category>
		<category><![CDATA[solr]]></category>
		<category><![CDATA[sql]]></category>
		<category><![CDATA[sqlite]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=9844</guid>
		<description><![CDATA[J'ai regardé le mouvement NoSQL évoluer au fil des années. On y retrouve à peu prêt tout ce qui fait l'informatique depuis que le monde IT est monde : brillance et troll, hype et génie, utile et gadget, buzz et fact, sam et max, etc.]]></description>
				<content:encoded><![CDATA[<p>J&#8217;ai regardé le mouvement NoSQL évoluer au fil des années. On y retrouve à peu près tout ce qui fait l&#8217;informatique depuis que le monde IT est monde : brillance et troll, hype et génie, utile et gadget, buzz et fact, sam et max, etc.</p>
<p>De plus on peut mettre n&#8217;importe quoi sous le label NoSQL, et du coup ça a été fait. En fait un fichier est déjà une base de données NoSQL :)</p>
<p>Mais rant mise à part, des projets comme redis, riak, elastic search ou mongodb changent vraiment la donne.</p>
<p>Malheureusement, tout comme d&#8217;autres technos du moment (prog asychrone, tout-http, pre-processeurs, generateurs&#8230;), les gens ont tendance à l&#8217;utiliser comme la barre de fer, la silver bullet, le passe-partout, le tournevis sonique, bref, le truc à tout faire.</p>
<p>L&#8217;adage populaire dit &#8220;quand on a un bon marteau, tous les problèmes ressemblent à des clous&#8221;. Or, je constate qu&#8217;au dessus de ça, les dev appliquent aussi souvent le dicton préféré d&#8217;un de mes colocs : &#8220;arrête de taper si fort, prend un plus gros marteau&#8221;. </p>
<p>Ca donne du NoSQL utilisé partout, pour tout, brandi comme LA solution, vendu à des débutants comme une panacée de traitement d&#8217;informations. Zob, vous vous doutez bien que ça pose problème, non ?</p>
<h2>Anti-fact 1 : NoSql, c&#8217;est plus facile pour démarrer</h2>
<p>Il n&#8217;existe pas à l&#8217;heure actuelle de base NoSQL embarquée qui arrive à la cheville de SQLite : ça marche partout, dans tous les langages, sans rien à avoir installer ou configurer pour la plupart des langages.</p>
<p>Dès que vous demandez à un débutant d&#8217;installer un truc, vous rajoutez une barrière d&#8217;entrée énorme.</p>
<p>De plus, il y a beaucoup, beaucoup, beaucoup plus d&#8217;hébergeurs qui fournissent du SQL que du NoSQL en solution par défaut. Et comme toute les technos legacy, il y a 100 fois plus de doc.</p>
<p>Enfin, il y a la fameuse question du &#8220;quoi&#8221; ? Quel système allez-vous installer ? Couch ? Casssandra ? Mongo ? On parle de NoSQL, ou de schemaless ? C&#8217;est pas la même chose ? Memcache et Redis, c&#8217;est que pour le cache ? Elastic Search, c&#8217;est que pour la recherche de texte ? Les données géographiques, je les mets dans quoi, mongo ou un GIS spécialisé ? Attends, j&#8217;ai entendu parler d&#8217;une super bdd de graph&#8230;</p>
<p>L&#8217;abondance de solutions, le manque de recul et les informations contradictoires disponibles rendent non seulement le choix difficile, mais en plus hasardeux. Car contrairement au monde du SQL, se gourrer en NoSQL peut vous pourir toute votre archi.</p>
<p>Souvenez-vous qu&#8217;il est beaucoup plus difficile de migrer son système de base de données NoSQL d&#8217;une solution à une autre car il n&#8217;y a pas ce petit détail en commun entre les produits : le SQL justement.</p>
<h2>Anti-fact 2 : Avec NoSql, pas besoin de réfléchir à son modèle de données</h2>
<p>Je crois que c&#8217;est ce qui me fait le plus grincer des dents. Les gens qui disent qu&#8217;on peut tout mettre dedans, hop, et on verra plus tard. J&#8217;ai vu les pires modèles de données possibles stockés en MongoDb ou Redis, parceque les gars qui avaient travaillé dessus avait juste dumpé leurs données sans réfléchir.</p>
<p>Une base NoSQL ne vous oblige pas à formaliser votre schéma, mais ça ne veut CERTAINEMENT PAS dire qu&#8217;il ne faut pas le faire. L&#8217;auteur de Redis a très bien <a rhef="http://oldblog.antirez.com/post/reply-open-minded-reader.html">expliqué le problème</a> (je graisse pour donner une effet dramatique et puissant au message) :</p>
<blockquote><p>Redis is not the kind of system where you can insert data and then argue about how to fetch those data in creative ways. Not at all, the whole idea of its data model, and part of the fact that it will be so fast to retrieve your data, is that <strong>you need to think in terms of organising your data for fetching</strong>. You need to design with the query patterns in mind.</p></blockquote>
<p>C&#8217;est vrai pour tout système dans lequel on met ses données, SQL, NoSQL, fichier, mémoire, le tiroir de votre bureau&#8230;</p>
<p>Il faut penser au type des données, leurs formats, les relations entre les éléments, comment et à quelle fréquence vous allez les écrire, les lire, garantir la consistence de leurs relations et leur fraicheur (ou pas d&#8217;ailleurs, mais il faut en faire le choix). Les bases SQL sont contraignantes parce qu&#8217;elles vous obligent à penser, dès le début, en ces termes.</p>
<p>C&#8217;est vrai, vous êtes de grandes personnes, a priori vous savez ce que vous faites, vous n&#8217;avez pas besoin qu&#8217;on vous FORCE à le faire. C&#8217;est pour ça que j&#8217;aime le typage dynamique. Je ne veux pas que tu me demandes mes papiers pour déclarer une variable, je sais ce que je fais.</p>
<p>Seulement <strong>il faut le faire</strong>, et ce n&#8217;est souvent pas fait. Pire, le modèle n&#8217;est généralement jamais formalisé NULLE PART. Un schéma, c&#8217;est une doc. Sans doc, le coût d&#8217;entrée dans votre projet est élevé, sa maintenance est galère, le potentiel de bug lors de l&#8217;évolution est plus grand. Mais une doc c&#8217;est chiant à écrire et à tenir à jour.</p>
<p>C&#8217;est un des intéressants effets secondaires des ORMs : les classes de définition sont le modèle documenté dans sa structure, ses relations, ses limites, ses contraintes, ses tests et vérifications, etc. La doc par le code, j&#8217;adore.</p>
<h2>Anti-fact 3 : NoSql, c&#8217;est plus performant</h2>
<p>A chaque fois qu&#8217;on lit &#8220;x est plus performant que z&#8221;, il faut faire une pause et réfléchir deux minutes. Généralement il y a un piège.</p>
<p>Les performances, ça dépend toujours du contexte. Par exemple, Redis est plus performant à la lecture et l&#8217;écriture, mais les données doivent tenir en RAM, sinon ça bouffe sur la mémoire virtuelle. Autre chose, Redis est très lent à démarrer sur des gros jeux de données (ça peut aller à plusieurs minutes si vous avez des Go). MongoDB doit normalement pouvoir tenir une augmentation de charge de manière prédictive en rajoutant des noeuds. Mais sur un seul noeud, c&#8217;est toujours moins performant qu&#8217;un PostGres. Et 0.01 % des sites ont besoin de plus d&#8217;un serveur.</p>
<p>Par ailleurs, les performances sont très dépendantes de l&#8217;anti-fact 2. Il faut créer les bons index, avoir un cache correctement ajusté, faire des requêtes intelligentes. Pour tous les systèmes.</p>
<p>Bref, encore une fois, NoSQL n&#8217;est pas une techno magique. Il est contre-productif, et j&#8217;ai envie de dire même irrespectueux envers ses collègues, de la vendre comme telle.</p>
<h2>Anti-fact 4 : NoSQL remplace le SQL</h2>
<p>Twitter tourne sur MySQL ET Memcache.</p>
<p>Stackoverflow utiliser SQL Server 2008 ET Redis.</p>
<p>Il y a carrément des sites qui <a href="http://www.plotprojects.com/why-we-use-postgresql-and-slick/">utilisent PostGres et MongoDb en parallèle</a>. En fait, il y a <a href="http://www.infoq.com/news/2013/02/MoSQL">des outils</a> pour les faire collaborer. </p>
<p>Nous sur notre plus gros site on utilise Redis pour les sessions, les compteurs, les crawlers, les queues et passer des données entre process. <strong>Pas juste pour le cache.</strong> On utilise PostGres pour les données complexes avec des queries lourdes. Et on utilise Solr pour le moteur de recherche. </p>
<p>Les bases NoSQL sont des nouveaux outils, qui sont mieux adaptés à CERTAINS usages ou à CERTAINS contextes. Pas tout, tout le temps, partout. C&#8217;est un outil en plus, pas un obligatoire remplaçant.</p>
<p>Par ailleurs, on peut utiliser PostGres comme une base de données <a href="http://thebuild.com/presentations/pg-as-nosql-pgday-fosdem-2013.pdf">clé-valeur</a> ou <a href="http://www.reddit.com/comments/1q3skb">JSON</a>, on peut mettre SQLite complètement en mémoire vive, on peut utiliser MySQL comme un moteur de recherche de texte&#8230; Multiplier les points of failures dans une archi n&#8217;est pas toujours une bonne idée. Ces outils qu&#8217;on considère comme de l&#8217;histoire ancienne ont beaucoup plus de ressource que vous ne l&#8217;imaginez. Ils sont ultra performants. Des années et des années d&#8217;optimisation.</p>
<p><a href="https://news.ycombinator.com/item?id=12529310">Le monde de la tech n&#8217;est jamais lisse</a>. Jamais.</p>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/nosql-arretons-de-dire-nimporte-quoi/feed/</wfw:commentRss>
		<slash:comments>39</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">9844</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2014/03/tumblr_n2sg6nrtxX1r539hzo1_500.jpg" length="80694" type="image/jpg" />	</item>
		<item>
		<title>Afficher le queryset d&#8217;une requête dans les logs SQL sous Django</title>
		<link>http://sametmax.com/afficher-le-queryset-dune-requete-dans-les-logs-sql-sous-django/</link>
		<comments>http://sametmax.com/afficher-le-queryset-dune-requete-dans-les-logs-sql-sous-django/#comments</comments>
		<pubDate>Wed, 25 Dec 2013 11:38:12 +0000</pubDate>
		<dc:creator><![CDATA[Max]]></dc:creator>
				<category><![CDATA[Programmation]]></category>
		<category><![CDATA[Web]]></category>
		<category><![CDATA[django]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[trace]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=8447</guid>
		<description><![CDATA[L'ORM de django pour les bases de données est chouette, agréable à utiliser mais construit des requêtes SQL qu'on ne peut reconnaître lors de l'analyse des logs MYSQL du premier coup d'oeil à moins d'avoir des années de pratique. J'ai une app django pour vous permettre de faire des débug sql éclairs !]]></description>
				<content:encoded><![CDATA[<p>C&#8217;est Noël, 2 articles rien que pour vous dont un <a href="http://sametmax.com/est-ce-que-framework-x-supporte-la-charge/" title="Est-ce que “framework x” supporte la charge ?">très interressant de Sam</a>.</p>
<p>L&#8217;ORM de django pour les bases de données est chouette, agréable à utiliser mais construit des requêtes SQL qu&#8217;on ne peut reconnaître lors de l&#8217;analyse des logs MYSQL du premier coup d&#8217;oeil. Et quand on a des centaines de requêtes par secondes c&#8217;est carrément impossible de s&#8217;y retrouver.</p>
<p>Ce que je vous propose ici c&#8217;est d&#8217;afficher le queryset (sa ligne et le fichier qui le contient) qui a permit d&#8217;exêcuter la requête SQL que vous voyez défiler dans les logs SQL sous forme de <a href="http://dev.mysql.com/doc/refman/5.0/en/comments.html">commentaires SQL</a>.</p>
<p>L&#8217;application se nomme <a href="https://pypi.python.org/pypi/django-sql-stacktrace/">Django Sql StackTrace</a>. C&#8217;est facile à installer et ça peut sauver des heures de debug.</p>
<p><strong>Installation Django Sql StackTrace:</strong></p>
<p><strong>Une bonne PIP comme toujours pour bien commencer.</strong></p>
<pre lang="bash">
pip install django-sql-stacktrace
</pre>
<p><strong>Dans votre fichier settings de django.</strong></p>
<pre lang="bash">
INSTALLED_APPS = (
    .........................
    'sqlstacktrace',
    .........................
)

SQL_STACKTRACE = True
</pre>
<p>La variable SQL_STACKTRACE sert à activer le debug.<br />
Pensez à le désactiver lorsque vous n&#8217;en avez pas besoin.</p>
<p><strong>Où se trouve mes super infos de debug ?</strong></p>
<p><a href="http://adw0rd.com/2012/8/23/django-sql-stacktrace/en/#.Urq_5mRdU98">D&#8217;après la doc</a> vous pouvez executer un <a href="http://pwet.fr/man/linux/commandes/watch">watch</a></p>
<pre lang="bash">
watch -n1 mysqladmin -u login -pmot_de_passe processlist --verbose
</pre>
<p>Chez moi ça n&#8217;a rien donné. Mais du côté des logs MySQL la magie a opérée.<br />
Vérifiez tout d&#8217;abord que vos logs sont activés dans mysql.</p>
<pre lang="bash">vi /etc/my.cnf</pre>
<pre lang="bash">
[mysqld]
......
log = /var/logs/mysql.log
......
</pre>
<p><strong>Comment on teste ça ?</strong></p>
<p>Redemarrez votre serveur web, surfez sur les pages de votre projet et observez les logs MySql. Vous deviez voir quelques chose de similaire:</p>
<pre lang="bash">
tail -F /var/logs/mysql.log
</pre>
<pre lang="bash">
		  644 Query	SELECT `auth_user`.`id`, `auth_user`.`password`, `auth_user`.`last_login`, `auth_user`.`is_superuser`, `auth_user`.`username`, `auth_user`.`first_name`, `auth_user`.`last_name`, `auth_user`.`email`, `auth_user`.`is_staff`, `auth_user`.`is_active`, `auth_user`.`date_joined` FROM `auth_user` WHERE `auth_user`.`id` = 65290
/* File "/Users/max/work/mon_projet/apps/mon_apps/views/others.py", line 146, in user_public_page
	user = User.objects.get(pk=user_id)
*/

</pre>
<p>Observez cette merveille !<br />
Entre <strong>/* */</strong> sont les infos générées par django-sql-stacktrace. J&#8217;ai nettoyé quelques fichiers pour plus de lisibilité.<br />
Vous avez droit au chemin du fichier de la requête, à la ligne de la requête et à la requête django elle-même.</p>
<p><strong>Une alternative ? J&#8217;ai pas envie d&#8217;installer d&#8217;app.</strong></p>
<p>Pour les grosses feignasses ou si vous voulez juste tester occasionnellement quelques queries vous pouvez utiliser la méthode extra pour ajouter vos propres commentaires.</p>
<pre lang="bash">
videos = Video.objects.filter(status='online').extra(where=['1=1 /* ceci apparaitra dans les logs mysql ! */'])
</pre>
<p>Cependant le WHERE 1=1 peut causer quelques baisses de performances, mais lorsqu&#8217;on est en debug en local ça peut servir !</p>
<p>PS: Je rappelle également le formidable outil <a href="https://github.com/django-debug-toolbar/django-debug-toolbar">django-debug-toolbar</a> qui devient vite indispensable.</p>
<p>Alors ? Elle est pas belle la vie ?</p>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/afficher-le-queryset-dune-requete-dans-les-logs-sql-sous-django/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">8447</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2013/12/fontaine_chocolat.jpg" length="26691" type="image/jpg" />	</item>
		<item>
		<title>La stack techno qu&#8217;on utilise pour faire un site Web, et pourquoi</title>
		<link>http://sametmax.com/la-stack-techno-quon-utilise-pour-faire-un-site-web-et-pourquoi/</link>
		<comments>http://sametmax.com/la-stack-techno-quon-utilise-pour-faire-un-site-web-et-pourquoi/#comments</comments>
		<pubDate>Mon, 11 Nov 2013 06:40:38 +0000</pubDate>
		<dc:creator><![CDATA[Sam]]></dc:creator>
				<category><![CDATA[Administration System]]></category>
		<category><![CDATA[celery]]></category>
		<category><![CDATA[django]]></category>
		<category><![CDATA[fabric]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[nginx]]></category>
		<category><![CDATA[nosql]]></category>
		<category><![CDATA[postgres]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[redis]]></category>
		<category><![CDATA[vm]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=7648</guid>
		<description><![CDATA[Une stack techno n'est pas une référence. Il n'y a pas de combo absolu qui rox absolument tout, c'est une question de contexte technique, financier, humain...

Mais c'est vrai que ça aide bien d'avoir sous les yeux les pratiques des autres.]]></description>
				<content:encoded><![CDATA[<p>Une stack techno n&#8217;est pas une référence. Il n&#8217;y a pas de combo absolu qui rox absolument tout, c&#8217;est une question de contexte technique, financier, humain&#8230;</p>
<p>Mais c&#8217;est vrai que ça aide bien d&#8217;avoir sous les yeux les pratiques des autres.</p>
<p>Je ne vais pas expliquer pourquoi Python, <a href="http://sametmax.com/10-raisons-pour-lesquelles-je-suis-toujours-marie-a-python/">je l&#8217;ai déjà fait</a>.</p>
<p>Commençons plutôt par la partie purement Web, pour laquelle on utilise Django, le framework Web Python.</p>
<p>Max et moi avons tout deux fait du PHP avant, j&#8217;ai tâté des frameworks internes, du Symfony et plus tard du Zope. J&#8217;ai regardé du côté de Pyramid et de ses prédécesseurs, et Django est celui qui me plaît le plus. J&#8217;ai juste un peu forcé la main à Max :-)</p>
<p>Car oui, le framework a été avant tout un choix de goût.</p>
<p>Ce n&#8217;est pas un choix de performances : le framework n&#8217;a aucun impact dessus. Aucun. Les architectures ont un impact. Le framework, non. Votre bottleneck sera sur les IO, pas sur le CPU. Le choix de technos asynchrones peut avoir un impact, mais ce n&#8217;est pas une question de framework. Tornado, Twisted ou NodeJS, on s&#8217;en fout. </p>
<p>Donc Django, essentiellement parce qu&#8217;il me plait. Et il me plaît pour ces raisons :</p>
<ul>
<li>Il y a un bon équilibre entre découplage et intégration. En général c&#8217;est soit très découplé et mal intégré, soit très bien intégré et très couplé.</li>
<li>C&#8217;est bien foutu et bien documenté. Et c&#8217;est stable. Vraiment très stable. Les core devs sont hyper sérieux.</li>
<li>C&#8217;est très versatile et ça peut faire plein de trucs out of the box, petits comme gros.</li>
<li>C&#8217;est assez facile à apprendre. Ça reste un framework, donc ce n&#8217;est pas la plus simple des démarches, mais dans le royaume des frameworks de cette taille, ça reste vraiment le plus simple.</li>
<li>La communauté est fantastique : il y a des centaines d&#8217;apps qui couvrent pratiquement tous les besoins.</li>
<li>Et bien entendu, c&#8217;est en Python.</li>
</ul>
<p>En terme de base de données, on a fait du MySQL pendant longtemps. Ça a plutôt bien marché. Maintenant je commence mes nouveaux projets avec PostGres, qui est plus solide. Parfois je fais juste du Sqlite, parce que ça suffit.</p>
<p>Pas de NoSQL. Après plusieurs expériences avec MongoDB et CouchDB, je n&#8217;ai pas été convaincu que les bénéfices dépassaient le coût. Il faudrait un article complet là-dessus (qu&#8217;on m&#8217;a d&#8217;ailleurs demandé).</p>
<p>Question OS. c&#8217;est du CentOS avec Max (il a plus l&#8217;habitude) ou du Ubuntu Server pour mes autres projets. Je reste sur les LTS. Ce n&#8217;est pas un choix très réfléchi, c&#8217;est surtout par habitude.</p>
<p>Pas de machine virtuelle. On a essayé, sans y trouver un grand intérêt :</p>
<ul>
<li>Il faut quand même faire des scripts de migration, donc autant s&#8217;en servir pour le déploiement.</li>
<li>On perd en perfs.</li>
<li>Les erreurs liées au mal-fonctionnement d&#8217;une VM sont absolument indébuggables.</li>
<li>Si on ne fait pas la VM soit-même, il faut mettre ses couilles dans les mains d&#8217;un prestataire de service. J&#8217;ai horreur de ça.</li>
<li>Trouver des gens avec la compétence pour gérer une VM, c&#8217;est difficile. Un script de déploiement, c&#8217;est du code que tout dev saura déjà lire. Par extension ça veut dire que je m&#8217;y replonge facilement des semaines plus tard.</li>
</ul>
<p>Et donc pour le déploiement, j&#8217;utilise <a href="http://sametmax.com/travailler-moins-pour-gagner-plus-en-15-minutes-avec-python-fabric/">fabric</a>, avec <a href="https://github.com/ronnix/fabtools/">fabtools</a>.</p>
<p>Ce n&#8217;est pas la solution la plus efficace, d&#8217;autant que ça limite à Python 2.7, mais c&#8217;est la plus simple. C&#8217;est juste du code Python. N&#8217;importe qui peut comprendre le déploiement en 15 minutes. Ça se modifie vite, s&#8217;adapte facilement. </p>
<p>Il faut comprendre qu&#8217;on a jamais plus d&#8217;une dizaine de serveurs pour un projet, ces choix sont donc faits en fonction de cela. Il va sans dire que si vous gérez un parc de centaines de machines, ça ne sera pas du tout le même choix technique. Peut être que Chef ou des VM seront alors carrément plus intéressants. Peut être que le NoSQL et sa capacité au scaling sera bien plus rentable.</p>
<p>Il ne s&#8217;agit pas de décrier les technos que nous n&#8217;utilisons pas. Il s&#8217;agit juste de dire, voilà les choix que nous avons faits, dans tel contexte, pour telles (bonnes ou mauvaises) raisons.</p>
<p>Durant les dernières années, on a ajouté <a href="http://redis.io/">Redis</a> à notre stack. C&#8217;est un outil fantastique qui sert à tout : de la base de données pour les trucs simples (il y a des fois ou un schéma est overkill) à la solution de caching. C&#8217;est ce qu&#8217;on a de plus proche du NoSQL.</p>
<p>L&#8217;outil est tellement simple à installer (vraiment le degré zero de la maintenance, c&#8217;est beau) et à utiliser que ça ne vaut juste pas le coup de s&#8217;en priver. </p>
<p>Du coup, plus de memcache. Toutes les grosses requêtes sont sauvegardées dans Redis, dès qu&#8217;on fait un script qui a besoin de persistance temporaire, Redis, pour communiquer entre plusieurs process, Redis, pour toutes les opérations qui ont besoin de grosses perfs comme les stats, Redis. Vive Redis.</p>
<p>D&#8217;ailleurs on utilise Redis aussi comme broker pour notre gestionnaire de queues et de taches : <a href="http://sametmax.com/files-de-taches-et-taches-recurrentes-avec-celery/">celery</a>. Si vous pythonez, je vous recommande chaudement celery pour toutes les tâches en background, les crawlers, les chaînes de process, etc.</p>
<p>On a aussi du moteur de recherche. Là on tape dans du <a href="http://lucene.apache.org/solr/">Solr</a> (avec <a href="http://haystacksearch.org/">haystack</a>). C&#8217;est très puissant, en tout cas syntaxiquement car ça ne fait pas de sémantique. Ne vous attendez donc pas à rattraper Google. Mais c&#8217;est aussi méga chiant à configurer et très lourd. Je pense qu&#8217;un jour on va migrer sur <a href="http://www.elasticsearch.org/">ElasticSearch</a>, mais c&#8217;est pas la priorité. Don&#8217;t fix what ain&#8217;t broken.</p>
<p>Devant tout ça on a <a href="http://nginx.org/">Nginx</a>. Comme beaucoup on a fait Apache => Cherokee => lighttp => nginx. Et franchement, je ne reviendrai jamais en arrière : plus léger, plus rapide, plus facile à installer et à configurer, plus versatile. Nginx fait tout, et mieux. </p>
<p>En proxy on a du <a href="http://gunicorn.org/">gunicorn</a>. Parce qu&#8217;on avait la flemme de configurer uwsgi et qu&#8217;on a pris l&#8217;habitude.</p>
<p>Après on utilise plein de libs, de petits outils, etc. Mais ça c&#8217;est le gros de notre archi.</p>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/la-stack-techno-quon-utilise-pour-faire-un-site-web-et-pourquoi/feed/</wfw:commentRss>
		<slash:comments>33</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">7648</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2013/11/nZ9b9.jpg" length="67160" type="image/jpg" />	</item>
		<item>
		<title>MySQL: créer un utilisateur avec une base de données à son nom sur laquelle il a tous les droits</title>
		<link>http://sametmax.com/mysql-creer-un-utilisateur-avec-une-table-a-son-nom-sur-laquelle-il-a-tous-les-droits/</link>
		<comments>http://sametmax.com/mysql-creer-un-utilisateur-avec-une-table-a-son-nom-sur-laquelle-il-a-tous-les-droits/#comments</comments>
		<pubDate>Mon, 15 Oct 2012 15:07:09 +0000</pubDate>
		<dc:creator><![CDATA[Sam]]></dc:creator>
				<category><![CDATA[Administration System]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[sql]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=2575</guid>
		<description><![CDATA[Le truc classique, qu'on fait tout le temps, et qu'on oublie toujours comment on a fait la dernière fois.]]></description>
				<content:encoded><![CDATA[<p>Le truc classique, qu&#8217;on fait tout le temps, et qu&#8217;on oublie toujours comment on a fait la dernière fois.</p>
<p>Vu qu&#8217;on a pas toujours PhpMyAdmin installé&#8230;</p>
<pre lang="sql">CREATE DATABASE nom_db;
GRANT ALL PRIVILEGES ON nom_db.* TO "nom_utilisateur"@"localhost" IDENTIFIED BY 'mot_de_passe';
FLUSH PRIVILEGES;</pre>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/mysql-creer-un-utilisateur-avec-une-table-a-son-nom-sur-laquelle-il-a-tous-les-droits/feed/</wfw:commentRss>
		<slash:comments>11</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">2575</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2012/10/xkcd.png" length="9340" type="image/jpg" />	</item>
		<item>
		<title>Optimiser Mysql en mettant en cache les requetes SELECT avec query_cache_size + benchmark</title>
		<link>http://sametmax.com/optimiser-mysql-en-utilisant-le-cache-query_cache_size/</link>
		<comments>http://sametmax.com/optimiser-mysql-en-utilisant-le-cache-query_cache_size/#comments</comments>
		<pubDate>Tue, 28 Aug 2012 23:25:24 +0000</pubDate>
		<dc:creator><![CDATA[Max]]></dc:creator>
				<category><![CDATA[Administration System]]></category>
		<category><![CDATA[benchmark]]></category>
		<category><![CDATA[cache]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[query_cache_size]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=1912</guid>
		<description><![CDATA[Petite astuce pour mettre en cache les requetes mysql à la lecture. Avantage: On a juste le fichier de conf mysql à éditer, pas besoin de toucher aux applications.]]></description>
				<content:encoded><![CDATA[<p>Voici une petite astuce pour mettre en cache les requetes mysql. Pour donner une idée du gain j&#8217;ai fait un petit script de benchmark, le gain à la lecture est plutôt convaincant. Je ne suis pas benchmarkeur de profession alors si il y en a dans la salle qui pensent que ce test n&#8217;est pas réaliste merci d&#8217;apporter votre contribution ;)</p>
<p><strong>Editer le fichier my.cnf pour activer le cache des requetes:</strong></p>
<pre lang="bash">query_cache_type = 1
query_cache_size = 256M</pre>
<p>query_cache_type est le type de cache que l&#8217;on va adopter:<br />
0 = pas de cache<br />
1 = met en cache toutes les requetes sauf celles qui ont le flag &#8220;SELECT S_NO_CACHE&#8221;<br />
2 = met en cache seulement les requetes qui comportent le flag &#8220;SELECT SQL_CACHE&#8221;</p>
<p><strong>Ci dessous le script pour tester les perfs:</strong></p>
<pre lang="python">#!/usr/bin/python
# -*- coding: utf-8 -*-

import MySQLdb as mdb
import sys

from timeit import Timer 

def benchmark(cur):
    """
        execute query
    """
    cur.execute("SELECT * FROM Writers")
    rows = cur.fetchall()
    #     for row in rows:
    #         print row

def create_fixtures():
    """
        Create dummy datas for test
    """

    with con:
        cur = con.cursor()
        cur.execute("DROP TABLE IF EXISTS Writers")
        cur.execute("CREATE TABLE IF NOT EXISTS Writers(Id INT PRIMARY KEY AUTO_INCREMENT, Name VARCHAR(25))")
        cur.execute("INSERT INTO Writers(Name) VALUES('Jack London')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Honore de Balzac')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Lion Feuchtwanger')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Emile Zola')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Adolf Hitler')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Ronald McDonalds')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Mamie Nova')")
        cur.execute("INSERT INTO Writers(Name) VALUES('Sam &amp; Max')")

def set_query_cache(query_cache_type=1):
    """
        Set query cache
        0 : Don't cache results in or retrieve results from the query cache.
        1 : Cache all query results except for those that begin with SELECT S_NO_CACHE.
        2 : Cache results only for queries that begin with SELECT SQL_CACHE
    """

    with con:
        cur = con.cursor()
        cur.execute("SET GLOBAL query_cache_size = 16777216")
        cur.execute("SET SESSION query_cache_type = %s" % str(query_cache_type)) 

def start_benchmark(nb_queries=1000, cached_queries=1):
    """

    """
    # use cached query benchmark
    print "Starting benchmark: %s reads - query cache type = %s" % (nb_queries, cached_queries)

    # set query cache
    set_query_cache(cached_queries)

    # run the test
    t = Timer("queries()", "from __main__ import queries")
    print t.timeit(number=nb_queries) 

if __name__ == '__main__':

    # connect to db
    con = mdb.connect('localhost', 'root', '12345', 'test');

    # create dummy datas
    create_fixtures()

    with con:
        cur = con.cursor()
        queries = lambda: benchmark(cur=cur)

    # launch benchmark
    start_benchmark(nb_queries=10000, cached_queries=1)
    start_benchmark(nb_queries=10000, cached_queries=0)

    con.close()</pre>
<p><strong>Ce qui me donne&#8230;</strong></p>
<pre lang="shell">python mysql_tests.py
Starting benchmark: 10000 reads - query cache type = 1
1.47591710091
Starting benchmark: 10000 reads - query cache type = 0
1.96538686752</pre>
<p><strong>Conclusion:</strong><br />
Il semblerait qu&#8217;en effet le gain dû au cache est plutôt pas mal, en plus c&#8217;est juste 2 params à mettre dans son fichier de config.</p>
<p>Faites part de vos retours, ça peut toujours servir ;)</p>
]]></content:encoded>
			<wfw:commentRss>http://sametmax.com/optimiser-mysql-en-utilisant-le-cache-query_cache_size/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">1912</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2012/08/asian-slut-bound-in-metal-fucking-machine.jpeg" length="21315" type="image/jpg" />	</item>
		<item>
		<title>Le backup wordpress du pauvre</title>
		<link>http://sametmax.com/le-backup-wordpress-du-pauvre/</link>
		<pubDate>Wed, 18 Jul 2012 15:36:09 +0000</pubDate>
		<dc:creator><![CDATA[Sam]]></dc:creator>
				<category><![CDATA[Administration System]]></category>
		<category><![CDATA[backup]]></category>
		<category><![CDATA[cron]]></category>
		<category><![CDATA[git]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[wordpress]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=1198</guid>
		<description><![CDATA[Quand c'est le blog que vous faites pour le fun, vous n'avez pas envie de mettre en place un système compliqué pour faire un backup facile à restaurer.]]></description>
				<content:encoded><![CDATA[<blockquote><p>Backup&#8217;s, can&#8217;t live with them, can&#8217;t live without them.</p></blockquote>
<p>Mais quand c&#8217;est le blog que vous faites pour le fun, vous n&#8217;avez pas envie de mettre en place un système compliqué pour faire un backup facile à restaurer.</p>
<p>Typiquement, SamEtMax est là pour le lulz, pas pour la corvée. Ce n&#8217;est pas grâve si il se fait pirater, defaced ou whatever. Pas besoin d&#8217;un truc hyper secure. Juste de quoi le remettre sur les rails rapidement, avec le minimum d&#8217;effort.</p>
<p>La solution inspirée par <a href="http://www.la-rache.com/">la méthode Rache</a>:</p>
<ul>
<li>Dans le cron: <code>28 22 * * 1 mysqldump -u user -ppassword database &gt; /chemin/vers/site/backup.sql</code></li>
<li>Un petit <code>git init</code>, <code>git add .</code>, <code>git commit -m "OSEF"</code>;</li>
<li>Un petit <code>git pull</code> sur son laptop (histoire d&#8217;avoir le code sous la main offline)</li>
</ul>
<p>Avec les thêmes le premier fetch fait quand même 250 Mo, le coquin.</p>
<p>Ensuite, un cron sur un autre server qui bouffe pas de BP (genre un server d&#8217;encoding) avec le <code>git pull</code> dedans, et voilà. Sauvegarde complète, automatique et facile à restaurer.</p>
]]></content:encoded>
		<post-id xmlns="com-wordpress:feed-additions:1">1198</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2012/07/Clay-Enos-African-child.jpg" length="111681" type="image/jpg" />	</item>
		<item>
		<title>Faire une sauvegarde de sa base de données Mysql</title>
		<link>http://sametmax.com/faire-une-sauvegarde-de-sa-base-de-donnees-mysql/</link>
		<pubDate>Tue, 17 Apr 2012 21:09:26 +0000</pubDate>
		<dc:creator><![CDATA[Max]]></dc:creator>
				<category><![CDATA[Programmation]]></category>
		<category><![CDATA[db]]></category>
		<category><![CDATA[dump]]></category>
		<category><![CDATA[mysql]]></category>
		<category><![CDATA[sauvegarde]]></category>

		<guid isPermaLink="false">http://sametmax.com/?p=419</guid>
		<description><![CDATA[Une chose à laquelle on pense rarement (enfin surtout qu'on ne fait pas par fainéantise) c'est sauvegarder les données générées sur le serveur, comme la base de données mysql par exemple. Voici une petite ligne de code qui pourrait bien vous sauver la vie]]></description>
				<content:encoded><![CDATA[<p>Une chose à laquelle on pense rarement (enfin surtout qu&#8217;on ne fait pas par fainéantise) c&#8217;est sauvegarder les données générées sur le serveur, comme la base de données mysql par exemple.</p>
<p>Voici une petite ligne de code que l&#8217;on met dans un cron et qui va saucegarder tous les lundis à 20h00 la base de données dans un répertoire de votre choix, vous pouvez également rajouter à la suite l&#8217;upload de cette sauvegarde sur un serveur de backup à l&#8217;aide de Rsync (<a href="http://sametmax.com/rsync-ou-comment-transferer-du-gros-contenu-via-ssh/">voir article sur Rsync</a>)</p>
<p>dans un crontab :</p>
<pre lang="bash">
00 20 * * 1 mysqldump -u DB_USERNAME -pDB_PASSWORD DB_NAME > /home/backup/db_name_backup.sql
</pre>
<p>où:<br />
DB_USERNAME = nom du&#8217;tilisateur pour se connecter à mysql<br />
DB_PASSWORD = mot de passe mysql<br />
DB_NAME = nom de la base de données mysql</p>
]]></content:encoded>
		<post-id xmlns="com-wordpress:feed-additions:1">419</post-id><enclosure url="http://sametmax.com/wp-content/uploads/2012/04/draft_lens18693734module154171018photo_1318532783backupyourdata.jpg" length="26941" type="image/jpg" />	</item>
	</channel>
</rss>
